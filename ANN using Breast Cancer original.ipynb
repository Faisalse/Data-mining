{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-41389fad42b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "data=pd.read_csv('data.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:31].values\n",
    "Y = data.iloc[:, 31].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding categorical data values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([506, 375, 361, 533, 216, 516, 328, 498, 485, 534, 330, 473, 462,\n",
       "        30, 530, 524, 306, 497, 202, 154, 300, 234, 448, 185, 426, 478,\n",
       "       520, 175, 444, 258, 439, 526, 336, 495, 513, 352, 458,  24,   0,\n",
       "       484, 136, 429, 471, 465, 431, 396, 173, 504, 319, 100,  53, 276,\n",
       "       172, 266, 252, 119, 318, 491,  31, 383, 273, 224, 496, 339, 467,\n",
       "       376, 402,  65, 502,  37,  56, 489, 523, 466, 198,  36, 141, 492,\n",
       "       450, 257, 371, 459, 476, 398, 260, 350,  92, 411, 409, 335, 151,\n",
       "        89,  27,  60, 309, 328, 167, 380, 360, 416, 170, 418,  94, 339,\n",
       "       187, 528, 390, 139, 440, 369, 333, 337, 488, 383, 460, 345, 225,\n",
       "       481, 518,  19, 343, 331, 271, 270, 208, 138, 256,  50, 235, 332,\n",
       "       407, 272, 204, 127, 199, 280, 164,  75, 137,  82, 293, 294, 284,\n",
       "       287,  77, 470, 466, 404, 217, 115,  40, 532, 519,  79, 352, 289,\n",
       "       229,  11, 255, 218, 266,  28, 406, 389, 397,  17, 222, 146, 412,\n",
       "        38,  78, 166, 456, 160,  22, 247, 500, 424,   5, 161, 282, 521,\n",
       "       351, 177, 438, 220, 103, 131,  54,  33, 531,  93,  52, 511, 356,\n",
       "       104, 414,  51, 405, 457, 295, 251, 362, 490, 359, 437, 168,  43,\n",
       "       486, 183,   6, 267,   2,  86, 464, 478, 327, 242, 312, 188, 357,\n",
       "       297, 365, 480, 205,  16, 313, 326, 428, 515, 386, 130, 159, 324,\n",
       "       298, 203, 355, 135, 238, 341,  47,  81, 522,  34, 201, 231, 142,\n",
       "       503, 292, 242, 248,  45, 522, 285, 377, 264, 453, 507, 461, 510,\n",
       "       268,  48, 184,  90, 190, 307, 192, 117, 126, 356,  20, 274, 372,\n",
       "       296, 262,  14,  35,   4,  29,  98, 436,  68, 237, 479, 135,  39,\n",
       "       452,  99, 113, 111, 366, 334, 427, 112, 101,  84,  66,  99, 215,\n",
       "        80, 446, 233, 422, 246, 210,  74, 329, 240,  26,  55, 108,   3,\n",
       "       311, 180, 286,  25,  15, 303, 477,   9, 435,  10, 347, 463, 265,\n",
       "        95, 129, 120, 304, 263, 391, 394,  49, 174, 143, 195, 455, 442,\n",
       "       213, 229, 364, 441, 388, 257, 241, 338, 283, 301, 363, 193,  87,\n",
       "       475, 367, 419, 116, 140, 322, 132, 179, 291,   1,  67, 149,  43,\n",
       "       191,  70, 209, 182,  46, 349, 430,  76, 354, 124, 223, 378, 509,\n",
       "       125, 432, 527, 403, 158, 415, 494, 162,  91, 368,  62, 472, 196,\n",
       "       225, 373, 461, 454, 128,  61, 219, 123, 393, 288, 508, 155, 152,\n",
       "       245,  12, 227, 114, 293, 342,  96, 230, 254, 399, 408,  23, 165,\n",
       "       320, 473, 421, 134, 317, 400, 177, 370, 271, 279, 433, 212, 129,\n",
       "        13, 499, 417, 281, 321,  88, 477, 228, 148,  97,  69, 425, 261,\n",
       "        85,  71, 308, 310, 387, 157, 181, 176, 449,  18, 302, 243, 163,\n",
       "       214, 145,  83,  32, 144, 385, 177,  42, 250, 102, 517, 295, 253,\n",
       "       512, 410, 344,  64, 314,  73, 487, 239, 249, 221, 395, 392, 226,\n",
       "       197, 413, 109, 299, 469,  58, 382, 275, 205, 305,   7, 206, 118,\n",
       "       178,  59, 468, 211, 420, 381, 346, 505, 186, 156, 518, 525, 370,\n",
       "       501, 147, 483, 445,  21, 493, 122, 106,  81, 250, 392, 374, 348,\n",
       "       379, 434, 200, 384, 401, 474, 353, 194, 153, 278, 232, 377, 236,\n",
       "        35, 315, 189, 325, 451, 447, 482, 290, 462, 107,  41, 340, 105,\n",
       "       171, 423, 259, 207,  57, 277,  44, 169, 150, 316,  72, 110, 269,\n",
       "       358, 323,   8, 529, 443, 133,  63, 244, 514, 121], dtype=int64)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load File \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign 357\n",
      "Malignanat 212\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### in order to check the quantity of dataset, we use graphical representation through seaborn library.This will show the \n",
    "### quantity of Benign and Malignent in the dataset and also visualize it.\n",
    "### seaborn is a graphical visualization library. with the help of library, we have to check the quantity of Benign or Malignent\n",
    "### this will give the quantity of Benign or Malignent\n",
    "import seaborn as sns\n",
    "ax = sns.countplot(data['diagnosis'],label= 'Count')\n",
    "B,M = data['diagnosis'].value_counts()\n",
    "print('Benign',B)\n",
    "print('Malignanat',M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### there is a attribute named as \"Unnamed :32\" which we have to drop \n",
    "\n",
    "del data['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Now we have to do Data Preprocessing\n",
    "### in Data Preprocessing we have to seperate the dependent and independent variable enclosed.\n",
    "### when we have categorical data, we have to deal with the missing value and how we fit the missing data.\n",
    "\n",
    "### X represent independent variable and y represent dependent variable\n",
    "### Except number 2 column, we are adding the column in X\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "### now we are doing encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "\n",
    "# Now we are spilting the dataset into training set and test set. test set is 10 percent and the remaining 90% we will use for\n",
    "## training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "## As we know whenever we use classification data, we have to convert into standard form. so that we have to make the number in\n",
    "## range. So therefore we are using standard form to make range between positive one and negative one.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65079907, -0.43057322, -0.68024847, ..., -0.36433881,\n",
       "         0.32349851, -0.7578486 ],\n",
       "       [-0.82835341,  0.15226547, -0.82773762, ..., -1.45036679,\n",
       "         0.62563098, -1.03071387],\n",
       "       [ 1.68277234,  2.18977235,  1.60009756, ...,  0.72504581,\n",
       "        -0.51329768, -0.96601386],\n",
       "       ...,\n",
       "       [-1.33114223, -0.22172269, -1.3242844 , ..., -0.98806491,\n",
       "        -0.69995543, -0.12266325],\n",
       "       [-1.25110186, -0.24600763, -1.28700242, ..., -1.75887319,\n",
       "        -1.56206114, -1.00989735],\n",
       "       [-0.74662205,  1.14066273, -0.72203706, ..., -0.2860679 ,\n",
       "        -1.24094654,  0.2126516 ]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "#now you are seeing the value lie between positive one and negative one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sequential is imported due to which classification technique we are using, depend upon step by step procedure  based and dense \n",
    "#is imported dur to add the layers .Input layer and hidden layer are added due to dense layer.\n",
    "#to handle the layers, we use dense layer.\n",
    "\n",
    "# Now it is time, to create node which mean layers which is used for input layer, hidden layer , output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding  the input and first hidden layer\n",
    "\n",
    "#Now we are visualizing the first hidden layer .independent variable on the basis which are making prediction. we are creating\n",
    "# the object \"classifier\"\n",
    "# Sequential variable is created. Sequential variable is created due to classifier variable.in sequential variable or model\n",
    "#we are creating ANN.\n",
    "## for layer adding, we are using function with classifier, classifier.add(Dense), Dense is used for layer adding.\n",
    "# for input layer we are using  input_dim, we have 20 input layer . input_dim=20\n",
    "# for hidden layer we are using output_dim,\n",
    "# in hidden layer, we are using activation function which is \"relu\"\n",
    "# for second hidden layer we are not using input_dim because we are now in hidden layer.\n",
    "#on output layer we have  two output that is Benign or Manigent. In output layer , we are using activitation function\n",
    "# which is sigmod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we have to ready the ANN and fit it to training set and we have trained the classifier through dense layer mean keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we have to ready the classifier and how he use optimize weight , which loss function he used , how he show accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f60d10320c91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# adding the input and first hidden layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#adding the second hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# adding the input and first hidden layer.\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation ='relu',input_dim=30))\n",
    "\n",
    "#adding the second hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "\n",
    "#adding the output layer\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimize mean that the algorithm which can automatic change the value of loss function according to.\n",
    "# less loss function then the predicted value is closer\n",
    "# when your outcome is binary then type of loss function  we used is binary_crossentropy.if outcome is multiple then\n",
    "#type of loss function is categorical_crossentropy\n",
    "#metrics is used for accuracy because it passes through different process then we will know the accuracy at training stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "426/426 [==============================] - 0s 316us/step - loss: 0.6785 - accuracy: 0.7324\n",
      "Epoch 2/10\n",
      "426/426 [==============================] - 0s 94us/step - loss: 0.4989 - accuracy: 0.9413\n",
      "Epoch 3/10\n",
      "426/426 [==============================] - 0s 96us/step - loss: 0.2299 - accuracy: 0.9531\n",
      "Epoch 4/10\n",
      "426/426 [==============================] - 0s 105us/step - loss: 0.1318 - accuracy: 0.9671\n",
      "Epoch 5/10\n",
      "426/426 [==============================] - 0s 110us/step - loss: 0.0990 - accuracy: 0.9742\n",
      "Epoch 6/10\n",
      "426/426 [==============================] - 0s 112us/step - loss: 0.0840 - accuracy: 0.9812\n",
      "Epoch 7/10\n",
      "426/426 [==============================] - 0s 98us/step - loss: 0.0760 - accuracy: 0.9789\n",
      "Epoch 8/10\n",
      "426/426 [==============================] - 0s 105us/step - loss: 0.0706 - accuracy: 0.9859\n",
      "Epoch 9/10\n",
      "426/426 [==============================] - 0s 98us/step - loss: 0.0668 - accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "426/426 [==============================] - 0s 94us/step - loss: 0.0638 - accuracy: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1edf75da4c8>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=10,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## for the visualization of test data, we are making it to boolean value so that we are able to make threshold so that if \n",
    "#the value is greater than threshold then it value is in true or false and it is easy to view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting the test set result\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87,  3],\n",
       "       [ 2, 51]], dtype=int64)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        90\n",
      "           1       0.94      0.96      0.95        53\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
